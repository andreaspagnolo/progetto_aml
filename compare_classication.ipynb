{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2118595,"sourceType":"datasetVersion","datasetId":1271215},{"sourceId":14484223,"sourceType":"datasetVersion","datasetId":9251284},{"sourceId":718609,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":546438,"modelId":559395}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9aa386cd","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport time\nimport shutil\n\n# --- 1. CONFIGURATION ---\nBATCH_SIZE = 32\nLR = 0.001\nEPOCHS = 10 \nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Path Setup\nPATH_TASK = '/kaggle/input/image-orientation-pretext-task-models/pytorch/default/1'\n\nmodel_configs = {\n    'resnet18': {\n        'CropMix':    f'{PATH_TASK}/fullTraining_ResNet18.pth',\n        'NoCropMix':  f'{PATH_TASK}/fullTraining_ResNet18_nocropmix.pth',\n        'FineTuning': f'{PATH_TASK}/fineTuning_ResNet18.pth',\n    },\n    'resnet50': {\n        'CropMix':    f'{PATH_TASK}/fullTraining_ResNet50.pth',\n        'NoCropMix':  f'{PATH_TASK}/fullTraining_ResNet50_nocropmix.pth',\n        'FineTuning': f'{PATH_TASK}/fineTuning_ResNet50.pth',\n    },\n    'efficientnet_b0': {\n        'CropMix':    f'{PATH_TASK}/fullTraining_EfficientNetB0.pth',\n        'NoCropMix':  f'{PATH_TASK}/fullTraining_EfficientNetB0_nocropmix.pth',\n        'FineTuning': f'{PATH_TASK}/fineTuning_EfficientNetB0.pth',\n    },\n    'efficientnet_b3': {\n        'CropMix':    f'{PATH_TASK}/fullTraining_EfficientNetB3.pth',\n        'NoCropMix':  f'{PATH_TASK}/fullTraining_EfficientNetB3_nocropmix.pth',\n        'FineTuning': f'{PATH_TASK}/fineTuning_EfficientNetB3.pth',\n    },\n    'inception_v3': {\n        'CropMix':    f'{PATH_TASK}/fullTraining_InceptionV3.pth',\n        'NoCropMix':  f'{PATH_TASK}/fullTraining_InceptionV3_nocropmix.pth',\n        'FineTuning': f'{PATH_TASK}/fineTuning_InceptionV3.pth',\n    },\n    'simple_CNN':{\n        'CropMix':    f'{PATH_TASK}/SimpleRotationCNN.pth',\n        'NoCropMix':  f'{PATH_TASK}/SimpleRotationCNN224_nocropmix.pth',\n    }\n}\n\nVOC_CLASSES = [\n    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', \n    'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', \n    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n]\n\n# --- 2. AUTOMATIC DATASET SETUP ---\ndef setup_voc_structure():\n    input_root = '/kaggle/input/pascal-voc-2012-dataset'\n    working_voc_dir = '/kaggle/working/VOCdevkit/VOC2012'\n    \n    if os.path.exists(working_voc_dir) and os.path.exists(os.path.join(working_voc_dir, 'JPEGImages')):\n        print(\"Dataset structure already exists.\")\n        return\n\n    print(\"Setting up VOC dataset structure...\")\n    source_voc_dir = None\n    for root, dirs, files in os.walk(input_root):\n        if 'JPEGImages' in dirs:\n            source_voc_dir = root\n            break\n            \n    if not source_voc_dir:\n        raise FileNotFoundError(\"Could not find VOC data in input!\")\n\n    os.makedirs(working_voc_dir, exist_ok=True)\n    \n    folders = ['Annotations', 'ImageSets', 'JPEGImages', 'SegmentationClass', 'SegmentationObject']\n    for folder in folders:\n        src = os.path.join(source_voc_dir, folder)\n        dst = os.path.join(working_voc_dir, folder)\n        if os.path.exists(src) and not os.path.exists(dst):\n            os.symlink(src, dst)\n            \n    print(\"Dataset setup complete.\")\n\nsetup_voc_structure()\n\n# --- 3. DATASET HANDLING & TRANSFORMS ---\nclass PascalVOC_Classification(datasets.VOCDetection):\n    def __init__(self, root, year, image_set, download=False, transform=None):\n        super().__init__(root, year, image_set, download=download, transform=transform)\n        self.class_to_idx = {name: i for i, name in enumerate(VOC_CLASSES)}\n\n    def __getitem__(self, index):\n        img, target = super().__getitem__(index)\n        label_vector = torch.zeros(20, dtype=torch.float32)\n        objects = target['annotation']['object']\n        if not isinstance(objects, list):\n            objects = [objects]\n        for obj in objects:\n            class_name = obj['name']\n            if class_name in self.class_to_idx:\n                idx = self.class_to_idx[class_name]\n                label_vector[idx] = 1.0\n        return img, label_vector\n\n# Define transforms\ntransform_standard = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntransform_efficientNetB3 = transforms.Compose([\n    transforms.Resize((300, 300)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntransform_inception = transforms.Compose([\n    transforms.Resize((299, 299)), \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Initialize Dataset\ntrain_dataset = PascalVOC_Classification(\n    root='/kaggle/working', \n    year='2012',\n    image_set='train',\n    download=False,\n    transform=transform_standard\n)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\n\n# --- 4. MODEL BUILDER (FIXED FOR INCEPTION) ---\ndef build_model(architecture, variant, custom_path=None):\n    # 1. Determine if we need AuxLogits (Only for Inception)\n    use_aux = False\n    if architecture == 'inception_v3':\n        if variant == 'NoCropMix' or variant == 'ImageNet':\n            use_aux = True\n    \n    # 2. Initialize Base Model\n    if variant == 'ImageNet':\n        model = getattr(models, architecture)(weights='DEFAULT')\n    else:\n        if architecture == 'inception_v3':\n            model = getattr(models, architecture)(weights=None, aux_logits=use_aux)\n        else:\n            model = getattr(models, architecture)(weights=None)\n    \n    # 3. Load Custom Weights\n    if variant in ['CropMix', 'NoCropMix', 'FineTuning'] and custom_path:\n        if not os.path.exists(custom_path):\n            print(f\"!! ERROR: File not found {custom_path}. Using Random weights !!\")\n        else:\n            print(f\"Loading {variant} weights from disk...\")\n            checkpoint = torch.load(custom_path, map_location='cpu')\n            state_dict = checkpoint.state_dict() if isinstance(checkpoint, nn.Module) else \\\n                         checkpoint.get('state_dict', checkpoint)\n            \n            if list(state_dict.keys())[0].startswith('module.'):\n                state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n            \n            filtered_dict = {k: v for k, v in state_dict.items() \n                             if not ('fc' in k or 'classifier' in k or 'AuxLogits' in k)}\n            try:\n                model.load_state_dict(filtered_dict, strict=False)\n            except Exception as e:\n                print(f\"Error loading {variant}: {e}\")\n\n    # 4. Replace Head(s) for VOC (20 Classes)\n    if 'resnet' in architecture:\n        model.fc = nn.Linear(model.fc.in_features, 20)\n    elif 'efficientnet' in architecture:\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 20)\n    elif 'inception' in architecture:\n        model.fc = nn.Linear(model.fc.in_features, 20)\n        # CRITICAL FIX: Resize Aux head if it exists\n        if hasattr(model, 'AuxLogits') and model.AuxLogits is not None:\n            model.AuxLogits.fc = nn.Linear(768, 20) \n\n    return model.to(DEVICE)\n\n\n# --- 5. TRAINING FUNCTION (UPDATED FOR ACCURACY) ---\ndef train_model(model, arch_name, variant_name):\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n    \n    loss_history = []\n    acc_history = []  # Store accuracy per epoch\n    \n    model.train()\n    print(f\"  Training {arch_name} [{variant_name}]...\")\n    \n    for epoch in range(EPOCHS):\n        running_loss = 0.0\n        running_corrects = 0\n        total_elements = 0\n        \n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            \n            # --- Dynamic Forward Pass ---\n            outputs = model(inputs)\n            \n            # Handle Inception Tuple (AuxLogits)\n            if isinstance(outputs, tuple):\n                main_out, aux_out = outputs\n                loss1 = criterion(main_out, labels)\n                loss2 = criterion(aux_out, labels)\n                loss = loss1 + 0.4 * loss2\n                logits_for_acc = main_out # Calculate accuracy on Main head only\n            else:\n                loss = criterion(outputs, labels)\n                logits_for_acc = outputs\n            \n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            \n            # --- Calculate Accuracy (Element-wise) ---\n            # Sigmoid > 0.5 is the standard threshold for Multi-label\n            preds = (torch.sigmoid(logits_for_acc) > 0.5).float()\n            \n            # Count correct elements (Hamming Score numerator)\n            # We compare the entire 20-length vector element by element\n            running_corrects += (preds == labels).sum().item()\n            total_elements += labels.numel() # Batch_Size * 20\n        \n        epoch_loss = running_loss / len(train_loader)\n        epoch_acc = running_corrects / total_elements\n        \n        loss_history.append(epoch_loss)\n        acc_history.append(epoch_acc)\n\n    return loss_history, acc_history\n\n\n# --- 6. EXECUTION LOOP (UPDATED FOR SUBPLOTS) ---\nVARIANTS_TO_TEST = ['CropMix', 'NoCropMix', 'FineTuning', 'ImageNet', 'Random']\n\nfor arch, paths in model_configs.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"ARCH: {arch}\")\n    print(f\"{'='*60}\")\n    \n    # 1. Handle Inception/EfficientNet Resize Logic\n    if arch == 'inception_v3':\n        print(f\">> Switching to 299x299 for {arch}\")\n        train_dataset.transform = transform_inception\n    elif arch == 'efficientnet_b3':\n        print(f\">> Switching to 300x300 for {arch}\")\n        train_dataset.transform = transform_efficientNetB3\n    elif train_dataset.transform != transform_standard:\n        print(f\">> Switching to 224x224 for {arch}\")\n        train_dataset.transform = transform_standard\n\n    # 2. Prepare Plot (1 Row, 2 Columns: Loss | Accuracy)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n    \n    for variant in VARIANTS_TO_TEST:\n        custom_path = paths.get(variant, None)\n        \n        # Build\n        model = build_model(arch, variant, custom_path)\n        \n        # Train & Record\n        start_t = time.time()\n        loss_hist, acc_hist = train_model(model, arch, variant)\n        duration = time.time() - start_t\n        \n        # Plot Loss on Left (ax1)\n        ax1.plot(loss_hist, label=f\"{variant}\", marker='.')\n        \n        # Plot Accuracy on Right (ax2)\n        ax2.plot(acc_hist, label=f\"{variant}\", marker='.')\n        \n        print(f\"    -> {variant} Done ({duration:.0f}s). Final Loss: {loss_hist[-1]:.4f} | Final Acc: {acc_hist[-1]:.4f}\")\n\n    # 3. Finalize Plots\n    # Loss Plot details\n    ax1.set_title(f'{arch} - Loss')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('BCE Loss')\n    ax1.legend()\n    ax1.grid(True)\n    \n    # Accuracy Plot details\n    ax2.set_title(f'{arch} - Accuracy')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Accuracy (Element-wise)')\n    ax2.legend()\n    ax2.grid(True)\n    \n    plt.show()\n\nprint(\"\\nAll comparisons complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T13:00:28.757730Z","iopub.execute_input":"2026-01-13T13:00:28.758405Z","iopub.status.idle":"2026-01-13T13:00:33.096620Z","shell.execute_reply.started":"2026-01-13T13:00:28.758371Z","shell.execute_reply":"2026-01-13T13:00:33.095345Z"}},"outputs":[{"name":"stdout","text":"Dataset structure already exists.\n\n============================================================\nARCH: resnet18\n============================================================\nLoading CropMix weights from disk...\n  Training resnet18 [CropMix]...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/898833250.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Train & Record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/898833250.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, arch_name, variant_name)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 0 Axes>"},"metadata":{}}],"execution_count":5}]}