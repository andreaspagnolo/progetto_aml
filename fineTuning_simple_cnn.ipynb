{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2118595,"sourceType":"datasetVersion","datasetId":1271215}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-02T15:09:46.550638Z","iopub.execute_input":"2026-01-02T15:09:46.550966Z","iopub.status.idle":"2026-01-02T15:09:47.349744Z","shell.execute_reply.started":"2026-01-02T15:09:46.550936Z","shell.execute_reply":"2026-01-02T15:09:47.349020Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Paths to VOC directories\nbase_dir = '/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val'\nimages_dir = os.path.join(base_dir, 'JPEGImages')\nannotations_dir = os.path.join(base_dir, 'Annotations')\nsets_dir = os.path.join(base_dir, 'ImageSets/Main')\n\n# Function to read predefined splits\ndef get_files_from_split(file_path):\n    with open(file_path, 'r') as f:\n        files = [x.strip().split()[0] for x in f.readlines() if not x.startswith('#')]\n    return files\n\n# Get all files from trainval.txt\ntrainval_files = get_files_from_split(os.path.join(sets_dir, 'trainval.txt'))\nnp.random.shuffle(trainval_files)  # Shuffle to randomize the split\n\nsplit_index = int(len(trainval_files) * 0.9)\ntrain_files = trainval_files[:split_index]\nval_files = trainval_files[split_index:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T15:09:48.350734Z","iopub.execute_input":"2026-01-02T15:09:48.351560Z","iopub.status.idle":"2026-01-02T15:09:48.402742Z","shell.execute_reply.started":"2026-01-02T15:09:48.351528Z","shell.execute_reply":"2026-01-02T15:09:48.402230Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport os\nimport random\nfrom torchvision import transforms\n\nclass RotationDataset(Dataset):\n    def __init__(self, file_list, root_dir, transform=None):\n        \"\"\"\n        file_list: lista dei nomi dei file (es. ['2008_000001', ...])\n        root_dir: cartella dove sono le immagini JPEG\n        \"\"\"\n        self.file_list = file_list\n        self.root_dir = root_dir\n        self.transform = transform\n        \n        # Mappa le rotazioni in classi\n        self.angle_to_label = {0: 0, 90: 1, 180: 2, 270: 3}\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        filename = self.file_list[idx]\n        img_path = os.path.join(self.root_dir, filename + \".jpg\")\n        \n        image = Image.open(img_path).convert(\"RGB\")\n        \n        # 1. Scegliamo una rotazione casuale\n        angle = random.choice([0, 90, 180, 270])\n        \n        # 2. Ruotiamo l'immagine\n        # Nota: expand=True adatta la dimensione se l'img non è quadrata\n        rotated_image = image.rotate(-angle, expand=True) \n        \n        # 3. Creiamo la label per la rotazione\n        label_rotation = self.angle_to_label[angle]\n        \n        # 4. Applichiamo le trasformazioni standard (Resize, ToTensor, Normalize)\n        if self.transform:\n            rotated_image = self.transform(rotated_image)\n            \n        return rotated_image, label_rotation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T15:09:51.325308Z","iopub.execute_input":"2026-01-02T15:09:51.325612Z","iopub.status.idle":"2026-01-02T15:09:51.333280Z","shell.execute_reply.started":"2026-01-02T15:09:51.325584Z","shell.execute_reply":"2026-01-02T15:09:51.332450Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Esempio di utilizzo\ntransform_pipeline = transforms.Compose([\n    transforms.Resize(300),\n    transforms.RandomResizedCrop(256),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Usa la tua lista 'train_files' generata nel tuo codice precedente\ntrain_dataset = RotationDataset(train_files, images_dir, transform=transform_pipeline)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T15:09:53.631049Z","iopub.execute_input":"2026-01-02T15:09:53.631630Z","iopub.status.idle":"2026-01-02T15:09:53.636362Z","shell.execute_reply.started":"2026-01-02T15:09:53.631598Z","shell.execute_reply":"2026-01-02T15:09:53.635520Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch.nn as nn\n\n# Model definition: SimpleCNN\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=4):\n        super(SimpleCNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            \n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            \n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(0.5),\n            nn.Linear(128 * 16 * 16, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T15:09:55.940959Z","iopub.execute_input":"2026-01-02T15:09:55.941553Z","iopub.status.idle":"2026-01-02T15:09:55.947711Z","shell.execute_reply.started":"2026-01-02T15:09:55.941520Z","shell.execute_reply":"2026-01-02T15:09:55.947064Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\nimport time\nimport copy\n\n# --- 1. CONFIGURAZIONE ---\nBATCH_SIZE = 32\nNUM_EPOCHS = 30\nLEARNING_RATE = 0.001\nPATIENCE = 3\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Usando device: {DEVICE}\")\n\n# --- 2. DATALOADERS ---\n# Creiamo il dataset di validazione (assicurati di aver definito val_files come prima)\nval_dataset = RotationDataset(val_files, images_dir, transform=transform_pipeline)\n\nimage_datasets = {\"train\": train_dataset,\n                  \"val\": val_dataset}\n\n# Creiamo i generatori di batch\n# --- 2. DATALOADERS ---\ndataloaders = {\n    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=2,pin_memory=True)\n    for x in [\"train\", \"val\"]\n}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n\n# --- 3. Creazione DEL MODELLO ---\nmodel = SimpleCNN(num_classes=4)\n\n# if torch.cuda.device_count() > 1:\n#     model = nn.DataParallel(model)\n#     print(torch.cuda.device_count(), \"devices\")\n    \nmodel = model.to(DEVICE)\n\n# --- 4. LOSS E OPTIMIZER ---\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n\n# --- 5. FUNZIONE DI TRAINING ---\ndef train_model(model):\n    start_time = time.time()\n    best_model = copy.deepcopy(model.state_dict())\n    best_val_loss = float(\"inf\")\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n    patience_counter = 0\n\n    for epoch in range(NUM_EPOCHS):\n        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n        print(\"-\" * 30)\n\n        for phase in [\"train\", \"val\"]:\n            model.train() if phase == \"train\" else model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == \"train\"):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                        \n                    _, preds = torch.max(outputs, 1)\n\n                    if phase == \"train\":\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n\n            if phase == \"train\":\n                history[\"train_loss\"].append(epoch_loss)\n                history[\"train_acc\"].append(epoch_acc.item())\n            else:\n                history[\"val_loss\"].append(epoch_loss)\n                history[\"val_acc\"].append(epoch_acc.item())\n                \n                scheduler.step()\n                if epoch_loss < best_val_loss:\n                    best_val_loss = epoch_loss\n                    best_model = copy.deepcopy(model.state_dict())\n                    patience_counter = 0\n                else:\n                    patience_counter += 1\n\n        if patience_counter >= PATIENCE:\n            print(\"Early stopping triggered.\")\n            break\n\n    time_elapsed = time.time() - start_time\n    print(f'Training completato in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n\n    model.load_state_dict(best_model)\n    return model, history\n\n# --- 6. AVVIO DEL TRAINING ---\ntrained_model, history = train_model(model)\n\n# --- 7. SALVATAGGIO DEL MODELLO ---\ntorch.save(trained_model.state_dict(), 'SimpleRotationCNN.pth')\nprint(\"Modello salvato come SimpleRotationCNN.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T15:09:58.610824Z","iopub.execute_input":"2026-01-02T15:09:58.611179Z","iopub.status.idle":"2026-01-02T15:53:48.548206Z","shell.execute_reply.started":"2026-01-02T15:09:58.611151Z","shell.execute_reply":"2026-01-02T15:53:48.547339Z"}},"outputs":[{"name":"stdout","text":"Usando device: cuda\n\nEpoch 1/30\n------------------------------\ntrain Loss: 1.3307 Acc: 0.3784\nval Loss: 1.3019 Acc: 0.4116\n\nEpoch 2/30\n------------------------------\ntrain Loss: 1.3004 Acc: 0.4035\nval Loss: 1.2756 Acc: 0.4142\n\nEpoch 3/30\n------------------------------\ntrain Loss: 1.2855 Acc: 0.4054\nval Loss: 1.2546 Acc: 0.4428\n\nEpoch 4/30\n------------------------------\ntrain Loss: 1.2698 Acc: 0.4159\nval Loss: 1.2616 Acc: 0.4445\n\nEpoch 5/30\n------------------------------\ntrain Loss: 1.2569 Acc: 0.4245\nval Loss: 1.2474 Acc: 0.4298\n\nEpoch 6/30\n------------------------------\ntrain Loss: 1.2483 Acc: 0.4302\nval Loss: 1.2215 Acc: 0.4289\n\nEpoch 7/30\n------------------------------\ntrain Loss: 1.2302 Acc: 0.4365\nval Loss: 1.2193 Acc: 0.4489\n\nEpoch 8/30\n------------------------------\ntrain Loss: 1.2207 Acc: 0.4466\nval Loss: 1.2014 Acc: 0.4653\n\nEpoch 9/30\n------------------------------\ntrain Loss: 1.2029 Acc: 0.4550\nval Loss: 1.1771 Acc: 0.4679\n\nEpoch 10/30\n------------------------------\ntrain Loss: 1.1885 Acc: 0.4586\nval Loss: 1.1648 Acc: 0.4714\n\nEpoch 11/30\n------------------------------\ntrain Loss: 1.1750 Acc: 0.4782\nval Loss: 1.1519 Acc: 0.4887\n\nEpoch 12/30\n------------------------------\ntrain Loss: 1.1846 Acc: 0.4776\nval Loss: 1.1245 Acc: 0.4974\n\nEpoch 13/30\n------------------------------\ntrain Loss: 1.1553 Acc: 0.4804\nval Loss: 1.1394 Acc: 0.5069\n\nEpoch 14/30\n------------------------------\ntrain Loss: 1.1352 Acc: 0.5048\nval Loss: 1.0872 Acc: 0.5442\n\nEpoch 15/30\n------------------------------\ntrain Loss: 1.1277 Acc: 0.5119\nval Loss: 1.0966 Acc: 0.5269\n\nEpoch 16/30\n------------------------------\ntrain Loss: 1.1155 Acc: 0.5203\nval Loss: 1.0741 Acc: 0.5234\n\nEpoch 17/30\n------------------------------\ntrain Loss: 1.1083 Acc: 0.5230\nval Loss: 1.0920 Acc: 0.5286\n\nEpoch 18/30\n------------------------------\ntrain Loss: 1.1008 Acc: 0.5245\nval Loss: 1.0825 Acc: 0.5451\n\nEpoch 19/30\n------------------------------\ntrain Loss: 1.1006 Acc: 0.5302\nval Loss: 1.0705 Acc: 0.5416\n\nEpoch 20/30\n------------------------------\ntrain Loss: 1.0854 Acc: 0.5350\nval Loss: 1.0928 Acc: 0.5425\n\nEpoch 21/30\n------------------------------\ntrain Loss: 1.0694 Acc: 0.5452\nval Loss: 1.0927 Acc: 0.5208\n\nEpoch 22/30\n------------------------------\ntrain Loss: 1.0684 Acc: 0.5456\nval Loss: 1.0486 Acc: 0.5676\n\nEpoch 23/30\n------------------------------\ntrain Loss: 1.0716 Acc: 0.5432\nval Loss: 1.0595 Acc: 0.5598\n\nEpoch 24/30\n------------------------------\ntrain Loss: 1.0632 Acc: 0.5496\nval Loss: 1.0624 Acc: 0.5633\n\nEpoch 25/30\n------------------------------\ntrain Loss: 1.0594 Acc: 0.5539\nval Loss: 1.0268 Acc: 0.5797\n\nEpoch 26/30\n------------------------------\ntrain Loss: 1.0436 Acc: 0.5621\nval Loss: 1.0629 Acc: 0.5451\n\nEpoch 27/30\n------------------------------\ntrain Loss: 1.0473 Acc: 0.5618\nval Loss: 1.0356 Acc: 0.5702\n\nEpoch 28/30\n------------------------------\ntrain Loss: 1.0361 Acc: 0.5630\nval Loss: 1.0394 Acc: 0.5615\nEarly stopping triggered.\nTraining completato in 43m 50s\nModello salvato come SimpleRotationCNN.pth\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model = SimpleCNN(num_classes=4)\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Totale parametri: {total_params}\")\nprint(f\"Parametri allenabili: {trainable_params}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T14:59:13.260047Z","iopub.execute_input":"2026-01-02T14:59:13.260742Z","iopub.status.idle":"2026-01-02T14:59:13.284307Z","shell.execute_reply.started":"2026-01-02T14:59:13.260692Z","shell.execute_reply":"2026-01-02T14:59:13.283593Z"}},"outputs":[{"name":"stdout","text":"Totale parametri: 765124\nParametri allenabili: 765124\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_training_results(history):\n    acc = history['train_acc']\n    val_acc = history['val_acc']\n    loss = history['train_loss']\n    val_loss = history['val_loss']\n    \n    # Creiamo un array con il numero delle epoche effettive\n    epochs_range = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(14, 5))\n\n    # --- GRAFICO 1: ACCURACY ---\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy', color='blue', marker='o', markersize=3)\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy', color='orange', marker='o', markersize=3)\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.grid(True, linestyle='--', alpha=0.6)\n\n    # --- GRAFICO 2: LOSS ---\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss', color='blue', marker='o', markersize=3)\n    plt.plot(epochs_range, val_loss, label='Validation Loss', color='orange', marker='o', markersize=3)\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True, linestyle='--', alpha=0.6)\n\n    plt.tight_layout()\n    plt.show()\n\n# Esegui la funzione passando la history ottenuta dal training\nif 'history' in locals():\n    plot_training_results(history)\nelse:\n    print(\"Errore: Variabile 'history' non trovata. Assicurati che la funzione di training la restituisca.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T13:28:22.77958Z","iopub.status.idle":"2025-12-31T13:28:22.779803Z","shell.execute_reply.started":"2025-12-31T13:28:22.779698Z","shell.execute_reply":"2025-12-31T13:28:22.779711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ndef plot_confusion_matrix(model, val_loader, class_names):\n    y_true = []\n    y_pred = []\n    \n    model.eval()\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs = inputs.to(DEVICE)\n            labels = labels.to(DEVICE)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            # Move to CPU and append to lists\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n            \n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Plot using Seaborn\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n# Define class names (based on your rotation angles)\nclass_names = ['0°', '90°', '180°', '270°']\n\n# Run the confusion matrix function\nplot_confusion_matrix(model, val_loader, class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T13:28:22.781057Z","iopub.status.idle":"2025-12-31T13:28:22.781369Z","shell.execute_reply.started":"2025-12-31T13:28:22.781207Z","shell.execute_reply":"2025-12-31T13:28:22.781225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. DATALOADERS ---\n# Creiamo il dataset di test (assicurati di aver definito test_files come prima)\nval_dataset = RotationDataset(val_files, images_dir, transform=transform_pipeline)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T13:28:22.783368Z","iopub.status.idle":"2025-12-31T13:28:22.783722Z","shell.execute_reply.started":"2025-12-31T13:28:22.783547Z","shell.execute_reply":"2025-12-31T13:28:22.783566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\nimport torch\nimport torch.nn.functional as F\n\ndef detailed_model_analysis(model, val_loader, class_names, device):\n    model.eval()\n    \n    # Store all labels and outputs\n    all_labels = []\n    all_preds = []\n    all_probs = [] # Raw probabilities for ROC\n    \n    # Store misclassified examples for visualization\n    # Format: (probability, predicted_class, true_class, image_tensor)\n    misclassified_examples = []\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            \n            # Apply Softmax to get probabilities (0 to 1)\n            probs = F.softmax(outputs, dim=1)\n            _, preds = torch.max(outputs, 1)\n            \n            # Save data\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n            \n            # Collect errors for visualization\n            # We look for cases where pred != label\n            matches = preds.eq(labels)\n            for i, is_correct in enumerate(matches):\n                if not is_correct:\n                    # Store data to visualize later\n                    # We store the confidence score of the WRONG prediction\n                    conf = probs[i][preds[i]].item()\n                    misclassified_examples.append({\n                        'conf': conf,\n                        'pred': preds[i].item(),\n                        'true': labels[i].item(),\n                        'img': inputs[i].cpu()\n                    })\n\n    # Convert to numpy arrays\n    y_true = np.array(all_labels)\n    y_pred = np.array(all_preds)\n    y_prob = np.array(all_probs)\n    n_classes = len(class_names)\n\n    # --- 1. Classification Report (F1, Precision, Recall) ---\n    print(\"1. CLASSIFICATION REPORT\")\n    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n\n    # --- 2. ROC Curves (One-vs-Rest) ---\n    print(\"2. GENERATING GENERAL ROC CURVE\")\n\n    # Binarize labels (e.g., 0 -> [1, 0, 0, 0])\n    y_true = np.array(all_labels)\n    y_probs = np.array(all_probs)\n    n_classes = len(class_names)\n    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n\n    # Compute Micro-Average ROC curve and ROC area\n    # .ravel() flattens the arrays to calculate metrics globally across all classes\n    fpr, tpr, _ = roc_curve(y_true_bin.ravel(), y_probs.ravel())\n    roc_auc = auc(fpr, tpr)\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, \n             label=f'General Micro-Average ROC (AUC = {roc_auc:0.3f})')\n    \n    plt.plot([0, 1], [0, 1], 'k--', lw=2) # Diagonal line (random guess)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('General ROC Curve for Full Training Model')\n    plt.legend(loc=\"lower right\")\n    plt.grid(alpha=0.3)\n    plt.show()\n\n    # --- 3. Top-Confidence Errors (Visual Inspection) ---\n    print(\"3. TOP CONFIDENT FAILURES (Visual Inspection)\")\n    print(\"These are images where the model was very confident but WRONG.\")\n    \n    # Sort errors by confidence (descending)\n    misclassified_examples.sort(key=lambda x: x['conf'], reverse=True)\n    \n    # Plot top 5 errors\n    num_show = min(5, len(misclassified_examples))\n    if num_show > 0:\n        fig, axes = plt.subplots(1, num_show, figsize=(15, 4))\n        if num_show == 1: axes = [axes]\n        \n        for i in range(num_show):\n            data = misclassified_examples[i]\n            \n            # Un-normalize image for display\n            # Assuming ImageNet stats: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n            img = data['img'].clone()\n            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n            img = img * std + mean\n            img = torch.clamp(img, 0, 1)\n            \n            # Display\n            ax = axes[i]\n            ax.imshow(img.permute(1, 2, 0).numpy())\n            ax.axis('off')\n            ax.set_title(f\"True: {class_names[data['true']]}\\nPred: {class_names[data['pred']]}\\nConf: {data['conf']:.2f}\", \n                         color='red', fontsize=10)\n        plt.show()\n    else:\n        print(\"No errors found! (100% Accuracy)\")\n\n# --- Run the Analysis ---\nclass_names = ['0°', '90°', '180°', '270°']\ndetailed_model_analysis(trained_model, val_loader, class_names, DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T13:28:22.785329Z","iopub.status.idle":"2025-12-31T13:28:22.785716Z","shell.execute_reply.started":"2025-12-31T13:28:22.785565Z","shell.execute_reply":"2025-12-31T13:28:22.785581Z"}},"outputs":[],"execution_count":null}]}