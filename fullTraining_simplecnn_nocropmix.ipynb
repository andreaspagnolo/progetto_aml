{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-11T14:16:57.411317Z",
     "iopub.status.busy": "2026-01-11T14:16:57.411047Z",
     "iopub.status.idle": "2026-01-11T14:16:58.349160Z",
     "shell.execute_reply": "2026-01-11T14:16:58.348238Z",
     "shell.execute_reply.started": "2026-01-11T14:16:57.411282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:17:03.633846Z",
     "iopub.status.busy": "2026-01-11T14:17:03.633534Z",
     "iopub.status.idle": "2026-01-11T14:17:03.658481Z",
     "shell.execute_reply": "2026-01-11T14:17:03.657959Z",
     "shell.execute_reply.started": "2026-01-11T14:17:03.633818Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths to VOC directories\n",
    "base_dir = '/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val'\n",
    "images_dir = os.path.join(base_dir, 'JPEGImages')\n",
    "annotations_dir = os.path.join(base_dir, 'Annotations')\n",
    "sets_dir = os.path.join(base_dir, 'ImageSets/Main')\n",
    "\n",
    "# Function to read predefined splits\n",
    "def get_files_from_split(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        files = [x.strip().split()[0] for x in f.readlines() if not x.startswith('#')]\n",
    "    return files\n",
    "\n",
    "# Get all files from trainval.txt\n",
    "trainval_files = get_files_from_split(os.path.join(sets_dir, 'trainval.txt'))\n",
    "np.random.shuffle(trainval_files)  # Shuffle to randomize the split\n",
    "\n",
    "split_index = int(len(trainval_files) * 0.9)\n",
    "train_files = trainval_files[:split_index]\n",
    "val_files = trainval_files[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:17:08.434091Z",
     "iopub.status.busy": "2026-01-11T14:17:08.433232Z",
     "iopub.status.idle": "2026-01-11T14:17:15.066057Z",
     "shell.execute_reply": "2026-01-11T14:17:15.065300Z",
     "shell.execute_reply.started": "2026-01-11T14:17:08.434061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "class RotationDataset(Dataset):\n",
    "    def __init__(self, file_list, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        file_list: lista dei nomi dei file (es. ['2008_000001', ...])\n",
    "        root_dir: cartella dove sono le immagini JPEG\n",
    "        \"\"\"\n",
    "        self.file_list = file_list\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Mappa le rotazioni in classi\n",
    "        self.angle_to_label = {0: 0, 90: 1, 180: 2, 270: 3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.file_list[idx]\n",
    "        img_path = os.path.join(self.root_dir, filename + \".jpg\")\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # 1. Scegliamo una rotazione casuale\n",
    "        angle = random.choice([0, 90, 180, 270])\n",
    "        \n",
    "        # 2. Ruotiamo l'immagine\n",
    "        # Nota: expand=True adatta la dimensione se l'img non è quadrata\n",
    "        rotated_image = image.rotate(-angle, expand=True) \n",
    "        \n",
    "        # 3. Creiamo la label per la rotazione\n",
    "        label_rotation = self.angle_to_label[angle]\n",
    "        \n",
    "        # 4. Applichiamo le trasformazioni standard (Resize, ToTensor, Normalize)\n",
    "        if self.transform:\n",
    "            rotated_image = self.transform(rotated_image)\n",
    "            \n",
    "        return rotated_image, label_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:17:18.937116Z",
     "iopub.status.busy": "2026-01-11T14:17:18.936292Z",
     "iopub.status.idle": "2026-01-11T14:17:18.942697Z",
     "shell.execute_reply": "2026-01-11T14:17:18.941736Z",
     "shell.execute_reply.started": "2026-01-11T14:17:18.937084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Esempio di utilizzo\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Usa la tua lista 'train_files' generata nel tuo codice precedente\n",
    "train_dataset = RotationDataset(train_files, images_dir, transform=transform_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:17:23.577324Z",
     "iopub.status.busy": "2026-01-11T14:17:23.576768Z",
     "iopub.status.idle": "2026-01-11T14:17:23.584228Z",
     "shell.execute_reply": "2026-01-11T14:17:23.583470Z",
     "shell.execute_reply.started": "2026-01-11T14:17:23.577292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Model definition: SimpleCNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:17:32.945835Z",
     "iopub.status.busy": "2026-01-11T14:17:32.945532Z",
     "iopub.status.idle": "2026-01-11T14:17:32.961333Z",
     "shell.execute_reply": "2026-01-11T14:17:32.960726Z",
     "shell.execute_reply.started": "2026-01-11T14:17:32.945808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = SimpleCNN(num_classes=4)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Totale parametri: {total_params}\")\n",
    "print(f\"Parametri allenabili: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:17:45.181774Z",
     "iopub.status.busy": "2026-01-11T14:17:45.181439Z",
     "iopub.status.idle": "2026-01-11T15:20:16.659101Z",
     "shell.execute_reply": "2026-01-11T15:20:16.658338Z",
     "shell.execute_reply.started": "2026-01-11T14:17:45.181746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# --- 1. CONFIGURAZIONE ---\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 75\n",
    "LEARNING_RATE = 0.01\n",
    "PATIENCE = 7\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando device: {DEVICE}\")\n",
    "\n",
    "# --- 2. DATALOADERS ---\n",
    "# Creiamo il dataset di validazione (assicurati di aver definito val_files come prima)\n",
    "val_dataset = RotationDataset(val_files, images_dir, transform=transform_pipeline)\n",
    "\n",
    "image_datasets = {\"train\": train_dataset,\n",
    "                  \"val\": val_dataset}\n",
    "\n",
    "# Creiamo i generatori di batch\n",
    "# --- 2. DATALOADERS ---\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=2,pin_memory=True)\n",
    "    for x in [\"train\", \"val\"]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
    "\n",
    "# --- 3. Creazione DEL MODELLO ---\n",
    "model = SimpleCNN(num_classes=4)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    print(torch.cuda.device_count(), \"devices\")\n",
    "    \n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# --- 4. LOSS E OPTIMIZER ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# --- 5. FUNZIONE DI TRAINING ---\n",
    "def train_model(model):\n",
    "    start_time = time.time()\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = float(\"inf\")\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            model.train() if phase == \"train\" else model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                        \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == \"train\":\n",
    "                history[\"train_loss\"].append(epoch_loss)\n",
    "                history[\"train_acc\"].append(epoch_acc.item())\n",
    "            else:\n",
    "                history[\"val_loss\"].append(epoch_loss)\n",
    "                history[\"val_acc\"].append(epoch_acc.item())\n",
    "                \n",
    "                scheduler.step()\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_loss\n",
    "                    best_model = copy.deepcopy(model.state_dict())\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Training completato in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model, history\n",
    "\n",
    "# --- 6. AVVIO DEL TRAINING ---\n",
    "trained_model, history = train_model(model)\n",
    "\n",
    "# --- 7. SALVATAGGIO DEL MODELLO ---\n",
    "torch.save(trained_model.state_dict(), 'SimpleRotationCNN.pth')\n",
    "print(\"Modello salvato come SimpleRotationCNN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T15:20:16.661318Z",
     "iopub.status.busy": "2026-01-11T15:20:16.660963Z",
     "iopub.status.idle": "2026-01-11T15:20:17.018235Z",
     "shell.execute_reply": "2026-01-11T15:20:17.017486Z",
     "shell.execute_reply.started": "2026-01-11T15:20:16.661284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_results(history):\n",
    "    acc = history['train_acc']\n",
    "    val_acc = history['val_acc']\n",
    "    loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    \n",
    "    # Creiamo un array con il numero delle epoche effettive\n",
    "    epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # --- GRAFICO 1: ACCURACY ---\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy', color='blue', marker='o', markersize=3)\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy', color='orange', marker='o', markersize=3)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- GRAFICO 2: LOSS ---\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss', color='blue', marker='o', markersize=3)\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss', color='orange', marker='o', markersize=3)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Esegui la funzione passando la history ottenuta dal training\n",
    "if 'history' in locals():\n",
    "    plot_training_results(history)\n",
    "else:\n",
    "    print(\"Errore: Variabile 'history' non trovata. Assicurati che la funzione di training la restituisca.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T15:34:50.162916Z",
     "iopub.status.busy": "2026-01-11T15:34:50.162292Z",
     "iopub.status.idle": "2026-01-11T15:34:50.166555Z",
     "shell.execute_reply": "2026-01-11T15:34:50.165869Z",
     "shell.execute_reply.started": "2026-01-11T15:34:50.162876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 2. DATALOADERS ---\n",
    "# Creiamo il dataset di test (assicurati di aver definito test_files come prima)\n",
    "val_dataset = RotationDataset(val_files, images_dir, transform=transform_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T15:36:16.652354Z",
     "iopub.status.busy": "2026-01-11T15:36:16.651661Z",
     "iopub.status.idle": "2026-01-11T15:36:27.564981Z",
     "shell.execute_reply": "2026-01-11T15:36:27.564310Z",
     "shell.execute_reply.started": "2026-01-11T15:36:16.652325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(model, val_loader, class_names):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Move to CPU and append to lists\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot using Seaborn\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Define class names (based on your rotation angles)\n",
    "class_names = ['0°', '90°', '180°', '270°']\n",
    "\n",
    "# Run the confusion matrix function\n",
    "plot_confusion_matrix(model, dataloaders['val'], class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T15:36:59.155629Z",
     "iopub.status.busy": "2026-01-11T15:36:59.155334Z",
     "iopub.status.idle": "2026-01-11T15:37:09.434648Z",
     "shell.execute_reply": "2026-01-11T15:37:09.433973Z",
     "shell.execute_reply.started": "2026-01-11T15:36:59.155604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def detailed_model_analysis(model, val_loader, class_names, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Store all labels and outputs\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = [] # Raw probabilities for ROC\n",
    "    \n",
    "    # Store misclassified examples for visualization\n",
    "    # Format: (probability, predicted_class, true_class, image_tensor)\n",
    "    misclassified_examples = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Apply Softmax to get probabilities (0 to 1)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Save data\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Collect errors for visualization\n",
    "            # We look for cases where pred != label\n",
    "            matches = preds.eq(labels)\n",
    "            for i, is_correct in enumerate(matches):\n",
    "                if not is_correct:\n",
    "                    # Store data to visualize later\n",
    "                    # We store the confidence score of the WRONG prediction\n",
    "                    conf = probs[i][preds[i]].item()\n",
    "                    misclassified_examples.append({\n",
    "                        'conf': conf,\n",
    "                        'pred': preds[i].item(),\n",
    "                        'true': labels[i].item(),\n",
    "                        'img': inputs[i].cpu()\n",
    "                    })\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_prob = np.array(all_probs)\n",
    "    n_classes = len(class_names)\n",
    "\n",
    "    # --- 1. Classification Report (F1, Precision, Recall) ---\n",
    "    print(\"1. CLASSIFICATION REPORT\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    # --- 2. ROC Curves (One-vs-Rest) ---\n",
    "    print(\"2. GENERATING GENERAL ROC CURVE\")\n",
    "\n",
    "    # Binarize labels (e.g., 0 -> [1, 0, 0, 0])\n",
    "    y_true = np.array(all_labels)\n",
    "    y_probs = np.array(all_probs)\n",
    "    n_classes = len(class_names)\n",
    "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "\n",
    "    # Compute Micro-Average ROC curve and ROC area\n",
    "    # .ravel() flattens the arrays to calculate metrics globally across all classes\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin.ravel(), y_probs.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'General Micro-Average ROC (AUC = {roc_auc:0.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2) # Diagonal line (random guess)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('General ROC Curve for Full Training Model')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # --- 3. Top-Confidence Errors (Visual Inspection) ---\n",
    "    print(\"3. TOP CONFIDENT FAILURES (Visual Inspection)\")\n",
    "    print(\"These are images where the model was very confident but WRONG.\")\n",
    "    \n",
    "    # Sort errors by confidence (descending)\n",
    "    misclassified_examples.sort(key=lambda x: x['conf'], reverse=True)\n",
    "    \n",
    "    # Plot top 5 errors\n",
    "    num_show = min(5, len(misclassified_examples))\n",
    "    if num_show > 0:\n",
    "        fig, axes = plt.subplots(1, num_show, figsize=(15, 4))\n",
    "        if num_show == 1: axes = [axes]\n",
    "        \n",
    "        for i in range(num_show):\n",
    "            data = misclassified_examples[i]\n",
    "            \n",
    "            # Un-normalize image for display\n",
    "            # Assuming ImageNet stats: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "            img = data['img'].clone()\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            img = img * std + mean\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            \n",
    "            # Display\n",
    "            ax = axes[i]\n",
    "            ax.imshow(img.permute(1, 2, 0).numpy())\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"True: {class_names[data['true']]}\\nPred: {class_names[data['pred']]}\\nConf: {data['conf']:.2f}\", \n",
    "                         color='red', fontsize=10)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No errors found! (100% Accuracy)\")\n",
    "\n",
    "# --- Run the Analysis ---\n",
    "class_names = ['0°', '90°', '180°', '270°']\n",
    "detailed_model_analysis(trained_model, dataloaders['val'], class_names, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1271215,
     "sourceId": 2118595,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
